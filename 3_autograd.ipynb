{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# <span style = 'color:cyan'>MANUAL</span>  CREATION OF LINEAR REGRESSION ALGORITM\r\n",
                "## There would be four parts -\r\n",
                "* **Prediction**\r\n",
                "* **Gradient Computation**\r\n",
                "* **Loss Computation**\r\n",
                "* **Parameter Update**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# <span style = 'color:cyan'> REPLACING MANUAL</span> CREATION OF LINEAR REGRESSION ALGORITM TO <span style = 'color:cyan'>AUTOMATION</span>\r\n",
                "## There would be four parts -\r\n",
                "* **Prediction : <span style = 'color:cyan'>Pytorch Model</span>**\r\n",
                "* **Gradient Computation : <span style = 'color:cyan'>Autograd</span>**\r\n",
                "* **Loss Computation : <span style = 'color:cyan'>Pytorch Loss</span>**\r\n",
                "* **Parameter Update : <span style = 'color:cyan'>Pytorch Optimizer</span>**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## This notebook will cover step 1 and 2 <span style = 'color:cyan'>(Prediction and Gradient Computation) manually and using pytorch</span>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **STEP 1 and 2 with Manual Implementation**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Linear Regression is a function with linear combination of weight and input.\r\n",
                "\r\n",
                "**ignore the bias for now**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 343,
            "source": [
                "import numpy as np"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 344,
            "source": [
                "X = np.array([1, 2, 3, 4], dtype = np.float32)      # Training Sample\r\n",
                "Y = np.array([2, 4, 6, 8], dtype = np.float32)      # Results\r\n",
                "w = 0.0                                            # Weight"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Model Prediction**\r\n",
                "no bias"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 345,
            "source": [
                "def forward(x):\r\n",
                "    return w*x\r\n",
                "    "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **loss = Mean Square Error (MSE)**\r\n",
                "$MSE = J = \\frac{1}{N}(wx-y)^2$     where N is number of elements in Y"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 346,
            "source": [
                "def loss(y, y_predicted):\r\n",
                "    return ((y_predicted - y)**2).mean()     "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Gradient**\r\n",
                "\r\n",
                "\r\n",
                "$\\frac{dJ}{dw} = \\frac{2x}{N}(wx-y)$\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 347,
            "source": [
                "def gradient(x, y, y_predicted):\r\n",
                "    return np.mean(2*x*(y_predicted-y))     # this is dJ/dw  "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Let's Predict the result before training. We can see that 'Y' is 2 times 'X'. So, the prediction of 5 has to be 10.**\r\n",
                "## **However, the weight 'w' is now 0. So, the result before the training would be 0.**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 348,
            "source": [
                "print(f'Prediction before Training : {forward(5):.3f}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Prediction before Training : 0.000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## TRAINING"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 349,
            "source": [
                "learning_rate = 0.05 \r\n",
                "number_of_iteration = 10\r\n",
                "for epoch in range(number_of_iteration):\r\n",
                "    # forward\r\n",
                "    y_pred = forward(X)\r\n",
                "    # loss # which is just to see the MSE of the function\r\n",
                "    l = loss(Y , y_pred)\r\n",
                "    # gradient\r\n",
                "    dw = gradient(X, Y, y_pred)\r\n",
                "    #update weight\r\n",
                "    w -= learning_rate * dw\r\n",
                "    print(f'epoch {epoch+1}, gradient is {dw:.3f}, weight is {w:.3f}, loss is {l:.3f}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "epoch 1, gradient is -30.000, weight is 1.500, loss is 30.000\n",
                        "epoch 2, gradient is -7.500, weight is 1.875, loss is 1.875\n",
                        "epoch 3, gradient is -1.875, weight is 1.969, loss is 0.117\n",
                        "epoch 4, gradient is -0.469, weight is 1.992, loss is 0.007\n",
                        "epoch 5, gradient is -0.117, weight is 1.998, loss is 0.000\n",
                        "epoch 6, gradient is -0.029, weight is 2.000, loss is 0.000\n",
                        "epoch 7, gradient is -0.007, weight is 2.000, loss is 0.000\n",
                        "epoch 8, gradient is -0.002, weight is 2.000, loss is 0.000\n",
                        "epoch 9, gradient is -0.000, weight is 2.000, loss is 0.000\n",
                        "epoch 10, gradient is -0.000, weight is 2.000, loss is 0.000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 350,
            "source": [
                "print(f'Prediction after Training : {forward(5):.3f}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Prediction after Training : 10.000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **STEP 1 and 2 with <span style='color:cyan'>Automation AKA Pytorch</span> Implementation**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 351,
            "source": [
                "import torch"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 352,
            "source": [
                "X = torch.tensor([1,2,3,4],dtype=torch.float32)\r\n",
                "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\r\n",
                "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 353,
            "source": [
                "def forward(x):\r\n",
                "    return w*x\r\n",
                "\r\n",
                "def loss(y, y_predicted):\r\n",
                "    return ((y_predicted - y)**2).mean()  "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 354,
            "source": [
                "learning_rate = 0.05 \r\n",
                "number_of_iteration = 10\r\n",
                "\r\n",
                "for epoch in range(number_of_iteration):\r\n",
                "    y_pred = forward(X)\r\n",
                "    l = loss(Y,y_pred)\r\n",
                "    l.backward()        # to calculate gradient (dl/dw)\r\n",
                "    #check in pytorch_intro.ipynb [29-31]\r\n",
                "    print(f'gradient is {w.grad}')\r\n",
                "    # the wrapper with torch.no_grad() temporarily sets all of the requires_grad flags to false.\r\n",
                "    # gradient should not be calculated when updating the weight.\r\n",
                "    with torch.no_grad():\r\n",
                "        w -= learning_rate * w.grad\r\n",
                "    # Has to empty out before next iteration\r\n",
                "    # check in pytorch_intro.ipynb [32-33]\r\n",
                "    w.grad.zero_()\r\n",
                "    print(f'epoch {epoch+1}, weight is {w:.3f}, loss is {l:.3f}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "gradient is -30.0\n",
                        "epoch 1, weight is 1.500, loss is 30.000\n",
                        "gradient is -7.5\n",
                        "epoch 2, weight is 1.875, loss is 1.875\n",
                        "gradient is -1.875\n",
                        "epoch 3, weight is 1.969, loss is 0.117\n",
                        "gradient is -0.46875\n",
                        "epoch 4, weight is 1.992, loss is 0.007\n",
                        "gradient is -0.1171875\n",
                        "epoch 5, weight is 1.998, loss is 0.000\n",
                        "gradient is -0.029296875\n",
                        "epoch 6, weight is 2.000, loss is 0.000\n",
                        "gradient is -0.00732421875\n",
                        "epoch 7, weight is 2.000, loss is 0.000\n",
                        "gradient is -0.0018310546875\n",
                        "epoch 8, weight is 2.000, loss is 0.000\n",
                        "gradient is -0.000457763671875\n",
                        "epoch 9, weight is 2.000, loss is 0.000\n",
                        "gradient is -0.00011444091796875\n",
                        "epoch 10, weight is 2.000, loss is 0.000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "9264711d228fe35bbbcc49f95b90edfc376310506fc14cf04059be83b6263525"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}