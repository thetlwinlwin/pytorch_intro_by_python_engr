{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### In previous cases, the data was loaded, training was looped over the number of epochs and then model was optimized based on the whole dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Above method is very <span style='color:cyan'>time consuming if we did gradient calculation</span> on the whole training data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The ideal way is to divided the large dataset into the samples into so-called <span style='color:cyan'>smaller batches</span>. We looped over the number of epochs and then ***loop over to all batched***. Then, we got the x and y batch samples and <span style='color:cyan'>do the optimization only on each batch</span>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TERMS\r\n",
    "* one epoch means one complete forward and backward pass of <span style='color:cyan'>ALL TRIAINGING SAMPLES</span>\r\n",
    "* batch_size = number of training samples in one forward & backward pass\r\n",
    "* no_of_iterations = number of passes, each pass using [batch_size] number of samples\r\n",
    "\r\n",
    "## eg. 100 samples, batch_size =20 --> 100/20 = 5 iterations for 1 epoch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import numpy as np\r\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class WineDataset(Dataset):\r\n",
    "    def __init__(self):\r\n",
    "        # data loading\r\n",
    "        xy = np.loadtxt('./dataset/wine.csv',delimiter=',',dtype=np.float32,skiprows=1)\r\n",
    "        self.x = torch.from_numpy(xy[:,1:])\r\n",
    "        self.y = torch.from_numpy(xy[:,[0]])\r\n",
    "        self.n_samples = xy.shape[0]\r\n",
    "        # putting zero in square bracket makes the dimension of y into two. y.shape => [no_of_samples,1]\r\n",
    "        \r\n",
    "        # if we did y = xy[:,0] => this will give one dimension\r\n",
    "        # y.shape => (no_of_samples,)\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "        # indexing dataset\r\n",
    "        return self.x[index],self.y[index]\r\n",
    "        # this will return a tuple\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        # len(dataset)\r\n",
    "        return self.n_samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## On Windows, due to multiprocessing restrictions, setting num_workers to > 0 will gives error.\r\n",
    "dataloader = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## dataloader will get 4 samples each time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "batch_size = 4\r\n",
    "dataset = WineDataset()\r\n",
    "dataloader = DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# creating an iterator object.\r\n",
    "data_iter = iter(dataloader)\r\n",
    "# generating data from iterator object.\r\n",
    "data = data_iter.next()\r\n",
    "features,labels = data\r\n",
    "print(f'shape of feature is {features.shape}\\n shape of label is {labels.shape}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape of feature is torch.Size([4, 13])\n",
      " shape of label is torch.Size([4, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# training parameter\r\n",
    "num_epochs = 2\r\n",
    "total_samples = len(dataset)\r\n",
    "n_iterations = math.ceil(total_samples/batch_size)\r\n",
    "print(total_samples,n_iterations)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for epoch in range(num_epochs):\r\n",
    "    for i, (inputs,labels) in enumerate(dataloader):\r\n",
    "        # forward backward, update\r\n",
    "        print(f'epoch {epoch+1}/{num_epochs},step {i+1}/{n_iterations},1st input data is {inputs[1,1]:.3f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1/2,step 1/45,1st input data is 3.450\n",
      "epoch 1/2,step 2/45,1st input data is 2.430\n",
      "epoch 1/2,step 3/45,1st input data is 1.170\n",
      "epoch 1/2,step 4/45,1st input data is 1.810\n",
      "epoch 1/2,step 5/45,1st input data is 4.280\n",
      "epoch 1/2,step 6/45,1st input data is 1.470\n",
      "epoch 1/2,step 7/45,1st input data is 1.660\n",
      "epoch 1/2,step 8/45,1st input data is 1.210\n",
      "epoch 1/2,step 9/45,1st input data is 1.130\n",
      "epoch 1/2,step 10/45,1st input data is 1.500\n",
      "epoch 1/2,step 11/45,1st input data is 2.450\n",
      "epoch 1/2,step 12/45,1st input data is 3.990\n",
      "epoch 1/2,step 13/45,1st input data is 1.610\n",
      "epoch 1/2,step 14/45,1st input data is 1.640\n",
      "epoch 1/2,step 15/45,1st input data is 1.590\n",
      "epoch 1/2,step 16/45,1st input data is 2.460\n",
      "epoch 1/2,step 17/45,1st input data is 4.430\n",
      "epoch 1/2,step 18/45,1st input data is 3.910\n",
      "epoch 1/2,step 19/45,1st input data is 1.010\n",
      "epoch 1/2,step 20/45,1st input data is 0.740\n",
      "epoch 1/2,step 21/45,1st input data is 1.730\n",
      "epoch 1/2,step 22/45,1st input data is 1.730\n",
      "epoch 1/2,step 23/45,1st input data is 1.350\n",
      "epoch 1/2,step 24/45,1st input data is 4.360\n",
      "epoch 1/2,step 25/45,1st input data is 1.600\n",
      "epoch 1/2,step 26/45,1st input data is 1.800\n",
      "epoch 1/2,step 27/45,1st input data is 5.650\n",
      "epoch 1/2,step 28/45,1st input data is 5.040\n",
      "epoch 1/2,step 29/45,1st input data is 1.890\n",
      "epoch 1/2,step 30/45,1st input data is 5.800\n",
      "epoch 1/2,step 31/45,1st input data is 1.700\n",
      "epoch 1/2,step 32/45,1st input data is 1.630\n",
      "epoch 1/2,step 33/45,1st input data is 1.330\n",
      "epoch 1/2,step 34/45,1st input data is 1.900\n",
      "epoch 1/2,step 35/45,1st input data is 1.650\n",
      "epoch 1/2,step 36/45,1st input data is 1.720\n",
      "epoch 1/2,step 37/45,1st input data is 1.480\n",
      "epoch 1/2,step 38/45,1st input data is 1.530\n",
      "epoch 1/2,step 39/45,1st input data is 1.860\n",
      "epoch 1/2,step 40/45,1st input data is 3.840\n",
      "epoch 1/2,step 41/45,1st input data is 0.920\n",
      "epoch 1/2,step 42/45,1st input data is 0.900\n",
      "epoch 1/2,step 43/45,1st input data is 4.100\n",
      "epoch 1/2,step 44/45,1st input data is 3.270\n",
      "epoch 1/2,step 45/45,1st input data is 3.430\n",
      "epoch 2/2,step 1/45,1st input data is 2.680\n",
      "epoch 2/2,step 2/45,1st input data is 3.900\n",
      "epoch 2/2,step 3/45,1st input data is 3.840\n",
      "epoch 2/2,step 4/45,1st input data is 2.400\n",
      "epoch 2/2,step 5/45,1st input data is 3.880\n",
      "epoch 2/2,step 6/45,1st input data is 3.830\n",
      "epoch 2/2,step 7/45,1st input data is 4.100\n",
      "epoch 2/2,step 8/45,1st input data is 3.910\n",
      "epoch 2/2,step 9/45,1st input data is 5.040\n",
      "epoch 2/2,step 10/45,1st input data is 1.130\n",
      "epoch 2/2,step 11/45,1st input data is 1.730\n",
      "epoch 2/2,step 12/45,1st input data is 2.120\n",
      "epoch 2/2,step 13/45,1st input data is 1.670\n",
      "epoch 2/2,step 14/45,1st input data is 1.880\n",
      "epoch 2/2,step 15/45,1st input data is 1.570\n",
      "epoch 2/2,step 16/45,1st input data is 4.040\n",
      "epoch 2/2,step 17/45,1st input data is 1.640\n",
      "epoch 2/2,step 18/45,1st input data is 1.250\n",
      "epoch 2/2,step 19/45,1st input data is 1.650\n",
      "epoch 2/2,step 20/45,1st input data is 1.590\n",
      "epoch 2/2,step 21/45,1st input data is 1.660\n",
      "epoch 2/2,step 22/45,1st input data is 1.870\n",
      "epoch 2/2,step 23/45,1st input data is 1.090\n",
      "epoch 2/2,step 24/45,1st input data is 1.100\n",
      "epoch 2/2,step 25/45,1st input data is 1.330\n",
      "epoch 2/2,step 26/45,1st input data is 1.890\n",
      "epoch 2/2,step 27/45,1st input data is 1.750\n",
      "epoch 2/2,step 28/45,1st input data is 3.240\n",
      "epoch 2/2,step 29/45,1st input data is 2.050\n",
      "epoch 2/2,step 30/45,1st input data is 2.390\n",
      "epoch 2/2,step 31/45,1st input data is 3.120\n",
      "epoch 2/2,step 32/45,1st input data is 1.680\n",
      "epoch 2/2,step 33/45,1st input data is 1.010\n",
      "epoch 2/2,step 34/45,1st input data is 2.670\n",
      "epoch 2/2,step 35/45,1st input data is 1.770\n",
      "epoch 2/2,step 36/45,1st input data is 3.030\n",
      "epoch 2/2,step 37/45,1st input data is 1.480\n",
      "epoch 2/2,step 38/45,1st input data is 1.670\n",
      "epoch 2/2,step 39/45,1st input data is 4.430\n",
      "epoch 2/2,step 40/45,1st input data is 3.980\n",
      "epoch 2/2,step 41/45,1st input data is 2.590\n",
      "epoch 2/2,step 42/45,1st input data is 1.130\n",
      "epoch 2/2,step 43/45,1st input data is 2.160\n",
      "epoch 2/2,step 44/45,1st input data is 2.150\n",
      "epoch 2/2,step 45/45,1st input data is 3.570\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "9264711d228fe35bbbcc49f95b90edfc376310506fc14cf04059be83b6263525"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}