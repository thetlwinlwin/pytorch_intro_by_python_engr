{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "import torch\r\n",
                "import torch.nn as nn\r\n",
                "import numpy as np \r\n",
                "from sklearn import datasets\r\n",
                "from sklearn.preprocessing import StandardScaler\r\n",
                "from sklearn.model_selection import train_test_split"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "source": [
                "bc = datasets.load_breast_cancer()\r\n",
                "#print(bc.DESCR) # description of datasets\r\n",
                "print('These are the feature names \\n',bc.feature_names)\r\n",
                "\r\n",
                "print('These are target names \\n',bc.target_names)\r\n",
                "print('These are bc dataset keys \\n',bc.keys())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "These are the feature names \n",
                        " ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
                        " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
                        " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
                        " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
                        " 'smoothness error' 'compactness error' 'concavity error'\n",
                        " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
                        " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
                        " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
                        " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
                        "These are target names \n",
                        " ['malignant' 'benign']\n",
                        "These are bc dataset keys \n",
                        " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "X,y = bc.data, bc.target\r\n",
                "\r\n",
                "print(f'Size of \"X\" is {X.shape}') \r\n",
                "print(f'Size of \"y\" is {y.shape}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Size of \"X\" is (569, 30)\n",
                        "Size of \"y\" is (569,)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "n_samples, n_features_in_X = X.shape\r\n",
                "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1212)\r\n",
                "\r\n",
                "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "(455, 30) (114, 30) (455,) (114,)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### <span style = 'color:cyan'>One of the recommandation to do in logistic regression is scaling down the features into around ***zero means*** and unit variance."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "# scaling the features\r\n",
                "sc = StandardScaler() \r\n",
                "X_train = sc.fit_transform(X_train)\r\n",
                "X_test = sc.transform(X_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "#convert to tensor\r\n",
                "X_train = torch.from_numpy(X_train.astype(np.float32))\r\n",
                "X_test = torch.from_numpy(X_test.astype(np.float32))\r\n",
                "y_train = torch.from_numpy(y_train.astype(np.float32))\r\n",
                "y_test = torch.from_numpy(y_test.astype(np.float32))\r\n",
                "\r\n",
                "print(X_train.shape)\r\n",
                "print(y_train.shape)\r\n",
                "print(f'y_train is dimension of {y_train.dim()}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([455, 30])\n",
                        "torch.Size([455])\n",
                        "y_train is dimension of 1\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## *y_train and y_test has to be converted into two dimensional tensor*"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "y_train = y_train.view(y_train.shape[0],1)\r\n",
                "y_test = y_test.view(y_test.shape[0],1)\r\n",
                "\r\n",
                "print(f'Now, the y_train has {y_train.dim()} dimension with shape of {y_train.shape}')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Now, the y_train has 2 dimension with shape of torch.Size([455, 1])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# f = sigmoid( $w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}+b$ )\r\n",
                "where n is number of features of one input in a sample training dataset.\r\n",
                "\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Whenever we create a model class, <span style = 'color:cyan'>forward method has to be implemented</span> so that when we call model ( as in [11] ) with the X_Train input, forward method will automatically calculated and return the predictions."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "class LogisticRegression(nn.Module):\r\n",
                "    def __init__(self,n_input_features,n_output_features):\r\n",
                "        super(LogisticRegression,self).__init__()\r\n",
                "        self.linear = nn.Linear(n_input_features,n_output_features)\r\n",
                "    \r\n",
                "    def forward(self,x):\r\n",
                "        y_predicted = torch.sigmoid(self.linear(x))\r\n",
                "        return y_predicted"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "# number of output feature is just one elements from target names.\r\n",
                "# That's why n_output_features is one.\r\n",
                "learning_rate = 0.01    \r\n",
                "num_epochs = 100\r\n",
                "model = LogisticRegression(n_input_features = n_features_in_X, n_output_features = 1)\r\n",
                "\r\n",
                "# parameters contains 30 features and a bias. as shown in above equation.\r\n",
                "for i in model.parameters():\r\n",
                "    print(i)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Parameter containing:\n",
                        "tensor([[ 0.1628, -0.0222, -0.0936,  0.1364,  0.0092, -0.1082,  0.0979, -0.0798,\n",
                        "          0.0214, -0.0205,  0.0337,  0.1451, -0.0889, -0.1425, -0.0605,  0.1439,\n",
                        "          0.0345, -0.1046,  0.0312, -0.0105, -0.1031,  0.0885, -0.0409, -0.0297,\n",
                        "          0.1754,  0.0812,  0.1216,  0.0406,  0.0666, -0.1464]],\n",
                        "       requires_grad=True)\n",
                        "Parameter containing:\n",
                        "tensor([-0.0742], requires_grad=True)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "# Binary Cross Entropy loss\r\n",
                "criterion = nn.BCELoss()\r\n",
                "#stochatic gradient decent\r\n",
                "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "source": [
                "for epoch in range(num_epochs):\r\n",
                "    y_pred = model(X_train)\r\n",
                "    loss = criterion(y_pred,y_train)\r\n",
                "    loss.backward()\r\n",
                "    optimizer.step()\r\n",
                "    optimizer.zero_grad()\r\n",
                "    if epoch %10 == 0:\r\n",
                "        print(f'In epoch {epoch+1}, loss is {loss.item():.3f}')\r\n",
                "        \r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "In epoch 1, loss is 0.774\n",
                        "In epoch 11, loss is 0.598\n",
                        "In epoch 21, loss is 0.496\n",
                        "In epoch 31, loss is 0.431\n",
                        "In epoch 41, loss is 0.386\n",
                        "In epoch 51, loss is 0.352\n",
                        "In epoch 61, loss is 0.326\n",
                        "In epoch 71, loss is 0.306\n",
                        "In epoch 81, loss is 0.289\n",
                        "In epoch 91, loss is 0.274\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "source": [
                "with torch.no_grad():\r\n",
                "    y_pred_on_X_test = model(X_test)\r\n",
                "    print(y_pred_on_X_test[0:5])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[0.8773],\n",
                        "        [0.7952],\n",
                        "        [0.8615],\n",
                        "        [0.6695],\n",
                        "        [0.8256]])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# <span style='color:cyan'>As we can see, model give us floating values. So, we have to add threshold.</span>\r\n",
                "## For example, in this case, we will round the output number. So, the threshold would be 0.5 "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "y_pred_on_X_test = y_pred_on_X_test.round()\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(0.9561)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "y_pred_on_X_test.eq(y_test) will give True if an element at *n* index from one tensor is equal to an element of correspoding index of another tensor."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Then, all the True values will be summed up and divided by the number of samples in test tensor."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "accuracy = y_pred_on_X_test.eq(y_test).sum()/float(y_test.shape[0])\r\n",
                "print(accuracy)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "9264711d228fe35bbbcc49f95b90edfc376310506fc14cf04059be83b6263525"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}